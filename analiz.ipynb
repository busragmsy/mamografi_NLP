{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"scw2JhwJX_ij","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1725107064965,"user_tz":-180,"elapsed":17335,"user":{"displayName":"İrem Kaya","userId":"17840275183276199790"}},"outputId":"c5e63902-2209-4a4b-ce8a-1fe74c5a2fbc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["!pip install pydicom\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y-0-a1MLZet1","executionInfo":{"status":"ok","timestamp":1725013843231,"user_tz":-180,"elapsed":1506,"user":{"displayName":"İrem Kaya","userId":"17840275183276199790"}},"outputId":"bc09d9e5-ed1e-4a33-e9dc-c62d4b0c17da","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pydicom in /usr/local/lib/python3.10/dist-packages (2.4.4)\n"]}]},{"cell_type":"code","source":["import os\n","import re\n","import string\n","import tensorflow as tf\n","from transformers import TFAutoModelForSequenceClassification, AutoTokenizer\n","from tensorflow.keras.optimizers import Adam\n","from sklearn.model_selection import train_test_split\n"],"metadata":{"id":"7RMngL-F1wpE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install -U tensorflow keras\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":967},"id":"b3c6ILTd5FfE","executionInfo":{"status":"ok","timestamp":1725014770355,"user_tz":-180,"elapsed":7275,"user":{"displayName":"İrem Kaya","userId":"17840275183276199790"}},"outputId":"8a4c3b0f-1121-4491-86f1-cd59772675a8","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.4.1)\n","Collecting keras\n","  Downloading keras-3.5.0-py3-none-any.whl.metadata (5.8 kB)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.11.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.1)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (71.0.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.8.0)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.12.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.8)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.7.4)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.0.4)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.16.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (2.1.5)\n","Downloading keras-3.5.0-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: keras\n","  Attempting uninstall: keras\n","    Found existing installation: keras 3.4.1\n","    Uninstalling keras-3.4.1:\n","      Successfully uninstalled keras-3.4.1\n","Successfully installed keras-3.5.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["keras"]},"id":"142501e141044050bcabff693d3d1e8f"}},"metadata":{}}]},{"cell_type":"code","source":["import os\n","import re\n","import string\n","import json\n","\n","def preprocess_text(text):\n","    \"\"\"\n","    Metin ön işleme fonksiyonu. Metni temizler ve normalleştirir.\n","    \"\"\"\n","    text = text.lower()\n","    text = re.sub(r'http\\S+', '', text)\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    text = re.sub(r'\\d+', '', text)\n","    return text.strip()\n","\n","def load_txt_data(folder_path):\n","    \"\"\"\n","    TXT dosyalarını yükler ve ön işler.\n","    \"\"\"\n","    reports, labels = [], []\n","\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".txt\"):\n","            file_path = os.path.join(folder_path, filename)\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                report = preprocess_text(file.read())\n","                if report:\n","                    reports.append(report)\n","                    labels.append(\"unknown\")  # Etiket mevcut değilse \"unknown\"\n","\n","    return reports, labels\n","\n","def load_jsonl_data(file_path):\n","    \"\"\"\n","    JSONL dosyasını yükler ve ön işler.\n","    \"\"\"\n","    reports, labels = [], []\n","\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        for line in file:\n","            data = json.loads(line)\n","            report = preprocess_text(data.get('report', ''))\n","            label = data.get('label', 'unknown')\n","            if report:\n","                reports.append(report)\n","                labels.append(label)\n","\n","    return reports, labels\n","\n","def load_all_data(base_folder):\n","    \"\"\"\n","    Tüm veri setlerini yükler ve birleştirir.\n","    \"\"\"\n","    all_reports, all_labels = [], []\n","\n","    # BIRADS raporlarını yükleme\n","    birads_base_folder = os.path.join(base_folder, '2000raporBIRADSgruplanmış')\n","    for subfolder in ['BIRADS1reports(n=50)', 'BIRADS2reports(n=400)', 'BIRADS3reports(n=450)', 'BIRADS4reports(n=550)', 'BIRADS5reports(n=550)']:\n","        subfolder_path = os.path.join(birads_base_folder, subfolder)\n","        reports, labels = load_txt_data(subfolder_path)\n","        all_reports.extend(reports)\n","        all_labels.extend(labels)\n","\n","    # NLPJSON klasöründen verileri yükleme\n","    for i in range(1, 5):\n","        jsonl_folder = os.path.join(base_folder, 'NLPJSON', str(i))\n","        jsonl_file = os.path.join(jsonl_folder, 'all.jsonl')\n","        if os.path.exists(jsonl_file):\n","            jsonl_reports, jsonl_labels = load_jsonl_data(jsonl_file)\n","            all_reports.extend(jsonl_reports)\n","            all_labels.extend(jsonl_labels)\n","\n","    # NLPTXT-1028 Etiketlenen Raporlar klasöründen verileri yükleme\n","    nlp_txt_base_folder = os.path.join(base_folder, 'NLPTXT-1028 Etiketlenen Raporlar')\n","    for subfolder in ['1', '2', '3', '4']:\n","        subfolder_path = os.path.join(nlp_txt_base_folder, subfolder)\n","        reports, labels = load_txt_data(subfolder_path)\n","        all_reports.extend(reports)\n","        all_labels.extend(labels)\n","\n","    return all_reports, all_labels\n","\n","# Verilerin yüklenmesi\n","base_folder = \"/content/drive/MyDrive/Colab Notebooks/VERİLER/NLP-Teknofest24\"\n","reports, labels = load_all_data(base_folder)\n","\n","print(f\"Yüklenen rapor sayısı: {len(reports)}\")\n","print(f\"Yüklenen etiket sayısı: {len(labels)}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"t2O2pASV2dHP","executionInfo":{"status":"error","timestamp":1725029146982,"user_tz":-180,"elapsed":1077,"user":{"displayName":"İrem Kaya","userId":"17840275183276199790"}},"outputId":"8017941d-e262-4e99-b6e9-d3fb659d7332"},"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/VERİLER/NLP-Teknofest24/2000raporBIRADSgruplanmış/BIRADS1reports(n=50)'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-0926b3aa4661>\u001b[0m in \u001b[0;36m<cell line: 85>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;31m# Verilerin yüklenmesi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0mbase_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/VERİLER/NLP-Teknofest24\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m \u001b[0mreports\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Yüklenen rapor sayısı: {len(reports)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-0926b3aa4661>\u001b[0m in \u001b[0;36mload_all_data\u001b[0;34m(base_folder)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msubfolder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'BIRADS1reports(n=50)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BIRADS2reports(n=400)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BIRADS3reports(n=450)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BIRADS4reports(n=550)'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'BIRADS5reports(n=550)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0msubfolder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbirads_base_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mreports\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_txt_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mall_reports\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreports\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mall_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-1-0926b3aa4661>\u001b[0m in \u001b[0;36mload_txt_data\u001b[0;34m(folder_path)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mreports\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/Colab Notebooks/VERİLER/NLP-Teknofest24/2000raporBIRADSgruplanmış/BIRADS1reports(n=50)'"]}]},{"cell_type":"code","source":["from collections import Counter\n","\n","def analyze_reports(reports):\n","    \"\"\"\n","    Raporların uzunluklarını ve genel özelliklerini analiz eder.\n","    \"\"\"\n","    lengths = [len(report) for report in reports]\n","    print(f\"Ortalama rapor uzunluğu: {sum(lengths) / len(lengths):.2f} karakter\")\n","    print(f\"En kısa rapor uzunluğu: {min(lengths)} karakter\")\n","    print(f\"En uzun rapor uzunluğu: {max(lengths)} karakter\")\n","\n","def analyze_labels(labels):\n","    \"\"\"\n","    Etiketlerin dağılımını analiz eder.\n","    \"\"\"\n","    label_counts = Counter(labels)\n","    print(\"Etiket Dağılımı:\")\n","    for label, count in label_counts.items():\n","        print(f\"{label}: {count}\")\n","\n","analyze_reports(reports)\n","analyze_labels(labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"10NXVXe1MVLz","executionInfo":{"status":"ok","timestamp":1725019807689,"user_tz":-180,"elapsed":669,"user":{"displayName":"İrem Kaya","userId":"17840275183276199790"}},"outputId":"9522edaf-e31d-402e-e976-8daec93512c0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ortalama rapor uzunluğu: 514.27 karakter\n","En kısa rapor uzunluğu: 203 karakter\n","En uzun rapor uzunluğu: 1214 karakter\n","Etiket Dağılımı:\n","unknown: 3028\n"]}]},{"cell_type":"code","source":["import os\n","import re\n","import string\n","import json\n","import pandas as pd\n","\n","def preprocess_text(text):\n","    \"\"\"\n","    Metin ön işleme fonksiyonu. Metni temizler ve normalleştirir.\n","    \"\"\"\n","    text = text.lower()\n","    text = re.sub(r'http\\S+', '', text)\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    text = re.sub(r'\\d+', '', text)\n","    return text.strip()\n","\n","def extract_birads_label(text):\n","    \"\"\"\n","    Metinden BIRADS etiketini çıkarmak için bir fonksiyon.\n","    \"\"\"\n","    for i in range(1, 6):\n","        if f'birads{i}' in text:\n","            return f'BIRADS{i}'\n","    return 'unknown'\n","\n","def load_txt_data(folder_path):\n","    \"\"\"\n","    TXT dosyalarını yükler ve ön işler.\n","    \"\"\"\n","    reports, labels = [], []\n","\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".txt\"):\n","            file_path = os.path.join(folder_path, filename)\n","            with open(file_path, 'r', encoding='utf-8') as file:\n","                report = preprocess_text(file.read())\n","                if report:\n","                    label = extract_birads_label(report)\n","                    reports.append(report)\n","                    labels.append(label)\n","\n","    return reports, labels\n","\n","def load_jsonl_data(file_path):\n","    \"\"\"\n","    JSONL dosyasını yükler ve ön işler.\n","    \"\"\"\n","    reports, labels = [], []\n","\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        for line in file:\n","            data = json.loads(line)\n","            report = preprocess_text(data.get('report', ''))\n","            label = extract_birads_label(report)\n","            if report:\n","                reports.append(report)\n","                labels.append(label)\n","\n","    return reports, labels\n","\n","def load_all_data(base_folder):\n","    \"\"\"\n","    Tüm veri setlerini yükler ve birleştirir.\n","    \"\"\"\n","    all_reports, all_labels = [], []\n","\n","    # BIRADS raporlarını yükleme\n","    birads_base_folder = os.path.join(base_folder, '2000raporBIRADSgruplanmış')\n","    for subfolder in ['BIRADS1reports(n=50)', 'BIRADS2reports(n=400)', 'BIRADS3reports(n=450)', 'BIRADS4reports(n=550)', 'BIRADS5reports(n=550)']:\n","        subfolder_path = os.path.join(birads_base_folder, subfolder)\n","        reports, labels = load_txt_data(subfolder_path)\n","        all_reports.extend(reports)\n","        all_labels.extend(labels)\n","\n","    # NLPJSON klasöründen verileri yükleme\n","    for i in range(1, 5):\n","        jsonl_folder = os.path.join(base_folder, 'NLPJSON', str(i))\n","        jsonl_file = os.path.join(jsonl_folder, 'all.jsonl')\n","        if os.path.exists(jsonl_file):\n","            jsonl_reports, jsonl_labels = load_jsonl_data(jsonl_file)\n","            all_reports.extend(jsonl_reports)\n","            all_labels.extend(jsonl_labels)\n","\n","    # NLPTXT-1028 Etiketlenen Raporlar klasöründen verileri yükleme\n","    nlp_txt_base_folder = os.path.join(base_folder, 'NLPTXT-1028 Etiketlenen Raporlar')\n","    for subfolder in ['1', '2', '3', '4']:\n","        subfolder_path = os.path.join(nlp_txt_base_folder, subfolder)\n","        reports, labels = load_txt_data(subfolder_path)\n","        all_reports.extend(reports)\n","        all_labels.extend(labels)\n","\n","    return all_reports, all_labels\n","\n","def analyze_data_lengths(reports, labels):\n","    \"\"\"\n","    Raporlar ve etiketler arasındaki uyumsuzlukları kontrol eder.\n","    \"\"\"\n","    if len(reports) != len(labels):\n","        print(f\"UYARI: Rapor sayısı ve etiket sayısı eşleşmiyor!\")\n","        print(f\"Rapor sayısı: {len(reports)}\")\n","        print(f\"Etiket sayısı: {len(labels)}\")\n","\n","        # Etiketlerin uyumsuzluklarını analiz et\n","        df = pd.DataFrame({'report': reports, 'label': labels})\n","        missing_labels = df[df['label'] == 'unknown']\n","        print(f\"Eksik etiketli rapor sayısı: {len(missing_labels)}\")\n","        print(\"Örnek eksik etiketli raporlar:\")\n","        print(missing_labels.head())\n","    else:\n","        print(f\"Rapor sayısı ve etiket sayısı eşleşiyor.\")\n","        print(f\"Toplam rapor sayısı: {len(reports)}\")\n","        print(f\"Toplam etiket sayısı: {len(labels)}\")\n","\n","# Verilerin yüklenmesi\n","base_folder = \"/content/drive/MyDrive/Colab Notebooks/VERİLER/NLP-Teknofest24\"\n","reports, labels = load_all_data(base_folder)\n","\n","# Verilerin uzunluğunu kontrol etme ve analiz yapma\n","analyze_data_lengths(reports, labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0nSHSJhBO2eL","executionInfo":{"status":"ok","timestamp":1725021691523,"user_tz":-180,"elapsed":16087,"user":{"displayName":"İrem Kaya","userId":"17840275183276199790"}},"outputId":"4abb75d7-8853-4b14-eb67-d51879f881a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Rapor sayısı ve etiket sayısı eşleşiyor.\n","Toplam rapor sayısı: 3026\n","Toplam etiket sayısı: 3026\n"]}]}]}